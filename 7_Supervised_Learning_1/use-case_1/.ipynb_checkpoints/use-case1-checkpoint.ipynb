{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20ae68ee-cf02-4a4d-bb99-46ba1735d58c",
   "metadata": {},
   "source": [
    "# Supervised learning 1\n",
    "## Use-Case 1: \n",
    "* Fit a model using binary classification using logistic regression. \n",
    "* Identify correlated variables and form a less complex model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df790d8-5d92-4404-841b-a2dbc02908dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# For Evaluation \n",
    "import sklearn.metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e52f7331-10cf-4e1b-9b7f-b3d18a004ac9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Reading the dataset using pandas\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvoice.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m data\u001b[38;5;241m.\u001b[39minfo()\n\u001b[0;32m      4\u001b[0m data\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Reading the dataset using pandas\n",
    "data=pd.read_csv('voice.csv')\n",
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e910544-468d-49bf-88bd-924d2fdeb43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50310b4-c44f-42e4-ab70-c35d3b6125bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encosing\n",
    "le = LabelEncoder()\n",
    "data['label']=le.fit_transform(data['label'])\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfbede7-8a18-4a89-b206-0037273c4adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bf5e00-feb8-46c4-be19-bff5927cb409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Divide the dataset into independent and dependent variables\n",
    "x=data.drop('label',axis=1)\n",
    "y=data['label']\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0692dd87-17b4-416d-b2d2-ad192c0ff989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split \n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2) \n",
    "print(x_train.shape,x_test.shape)\n",
    "print(y_train.shape,y_test.shape)\n",
    "print(x_train.head())\n",
    "print(x_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05b3450-8735-45fb-8ebe-e7c9e6017a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the Features: Logistic regression performs better when the features are on a similar scale. \n",
    "# Standardize the features using StandardScaler before training:\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3290f518-08bc-40a3-84ad-424b4fcede0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic regression model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a3d78a-95c7-42e2-9927-e81fb02fb5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking prediction accuracy (Known data)\n",
    "print(log_reg)\n",
    "y_pred=log_reg.predict(x_train)\n",
    "print(y_pred)\n",
    "print(\"Train accuracy: \", sklearn.metrics.accuracy_score(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b4136f-b203-4e95-8b68-710fd6a6065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking prediction accuracy (UnKnown data)\n",
    "y_pred=log_reg.predict(x_test)\n",
    "print(y_pred)\n",
    "print(\"Test accuracy: \", sklearn.metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed894229-1ffe-4b7e-8017-f96408708479",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data.corr()\n",
    "plt.figure(figsize=(14,14))\n",
    "sns.heatmap(corr, cbar = True,  square = True,\n",
    "            cmap= 'coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572a8670-902a-4489-9396-4316ca554775",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = x.corr()\n",
    "plt.figure(figsize=(14,14))\n",
    "sns.heatmap(corr, cbar = True,  square = True,\n",
    "            cmap= 'coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6699cb1b-2ac5-4552-8a6b-aa6d178df664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features for the model ( remove collinearity)\n",
    "# Removing multicollinearity helps achieve more stable, interpretable, and reliable coefficients.\n",
    "# When highly correlated features are present in a logistic regression model, it can cause instability in the model’s coefficients.\n",
    "# Instability increases the variance of the model, making it sensitive to small changes in the data and leading to a less generalizable model\n",
    "# Consistent Feature Selection: Automate this feature selection by dropping one variable from each highly correlated pair. \n",
    "high_corr = corr[corr.abs() > 0.8]  # Using 0.8 as threshold for high correlation\n",
    "correlated_features = set()\n",
    "for i in range(len(high_corr.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(high_corr.iloc[i, j]) > 0.8:  # Identify pairs above threshold\n",
    "            colname = high_corr.columns[i]\n",
    "            correlated_features.add(colname)\n",
    "\n",
    "print(\"Correlated features: \", correlated_features)\n",
    "x_reduced = x.drop(labels=correlated_features, axis=1)\n",
    "print(\"Remaining features in x_reduced:\", x_reduced.columns.tolist())\n",
    "\n",
    "# Removing highly correlated features simplifies the model, stabilizes the logistic regression coefficients, and enhances generalization. \n",
    "# This approach ensures that the model is interpreting each feature independently, providing a clearer and more robust relationship with the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa00bd9c-afc5-48bd-bc88-b2b74d89deb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split \n",
    "x_train,x_test,y_train,y_test=train_test_split(x_reduced,y,test_size=0.2) \n",
    "print(x_train.shape,x_test.shape)\n",
    "print(y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3db305-2926-4d8c-a46f-a5dcff7752e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the Features: Logistic regression performs better when the features are on a similar scale. \n",
    "# Standardize the features using StandardScaler before training:\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51bd790-6b3b-49cd-85d4-07e2fa0d232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic regression model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(x_train,y_train)\n",
    "print(log_reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8085880-d741-4dda-8c63-8c36b74dcf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking prediction accuracy (Known data)\n",
    "print(log_reg)\n",
    "y_pred=log_reg.predict(x_train)\n",
    "print(y_pred)\n",
    "print(\"Reduced Model Train accuracy: \", sklearn.metrics.accuracy_score(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d2fec9-3b97-4711-8e4d-4119a063da11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking prediction accuracy (UnKnown data)\n",
    "y_pred=log_reg.predict(x_test)\n",
    "print(y_pred)\n",
    "print(\"Reduced Model Test accuracy: \", sklearn.metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64c74fd-beb3-407e-958d-e98e9bfb087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Cross-Validation: To further validate the model, you might consider using cross-validation to ensure that the model’s performance is consistent. \n",
    "# Use cross_val_score from sklearn.model_selection:\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(log_reg, x_reduced, y, cv=5)\n",
    "print(\"Cross-validated scores on reduced model:\", scores)\n",
    "print(\"Mean cross-validation score:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b20570f-7794-4d5c-a274-b9516818439d",
   "metadata": {},
   "source": [
    "### Cross-validation scores\n",
    "The cross-validation scores obtained represent the accuracy of the logistic regression model on the reduced feature set across each fold in a 5-fold cross-validation.\n",
    "* Cross-validation helps ensure that the model’s performance is consistent across different subsets of the data, reducing the chance of overfitting or underfitting.\n",
    "* It provides a more robust measure of model accuracy than a single train-test split, especially for smaller datasets or when evaluating model stability.In your case, an average score of approximately 84.25% suggests that the model is fairly accurate with the reduced feature set, though the score may be slightly lower than when using the full feature set.\n",
    "* Variations between the scores (e.g., 0.7003 in one fold versus 0.9385 in another) may indicate that model performance varies depending on the data split. Consistency across scores usually indicates more stable performance.\n",
    "* The mean cross-validation score, 0.8425 (or about 84.25%), is the average accuracy across all five folds.\n",
    "* This value gives a good estimate of how well the model is expected to perform on unseen data, providing a more reliable measure than a single train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7a93af-c194-4db7-974c-d35fb751f7ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
