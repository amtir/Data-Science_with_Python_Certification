{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71133460-dbba-4557-80e5-15e4334d322b",
   "metadata": {},
   "source": [
    "\n",
    "# Module 9: Supervised Learning II\n",
    "## Case Study â€“ 1\n",
    "\n",
    "### Objective: \n",
    " * Classifying Voice Samples as Male or Female. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97849338-d0ec-4568-9641-58bc9ecc6cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 21 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   meanfreq  3168 non-null   float64\n",
      " 1   sd        3168 non-null   float64\n",
      " 2   median    3168 non-null   float64\n",
      " 3   Q25       3168 non-null   float64\n",
      " 4   Q75       3168 non-null   float64\n",
      " 5   IQR       3168 non-null   float64\n",
      " 6   skew      3168 non-null   float64\n",
      " 7   kurt      3168 non-null   float64\n",
      " 8   sp.ent    3168 non-null   float64\n",
      " 9   sfm       3168 non-null   float64\n",
      " 10  mode      3168 non-null   float64\n",
      " 11  centroid  3168 non-null   float64\n",
      " 12  meanfun   3168 non-null   float64\n",
      " 13  minfun    3168 non-null   float64\n",
      " 14  maxfun    3168 non-null   float64\n",
      " 15  meandom   3168 non-null   float64\n",
      " 16  mindom    3168 non-null   float64\n",
      " 17  maxdom    3168 non-null   float64\n",
      " 18  dfrange   3168 non-null   float64\n",
      " 19  modindx   3168 non-null   float64\n",
      " 20  label     3168 non-null   object \n",
      "dtypes: float64(20), object(1)\n",
      "memory usage: 519.9+ KB\n",
      "None\n",
      "meanfreq    0\n",
      "sd          0\n",
      "median      0\n",
      "Q25         0\n",
      "Q75         0\n",
      "IQR         0\n",
      "skew        0\n",
      "kurt        0\n",
      "sp.ent      0\n",
      "sfm         0\n",
      "mode        0\n",
      "centroid    0\n",
      "meanfun     0\n",
      "minfun      0\n",
      "maxfun      0\n",
      "meandom     0\n",
      "mindom      0\n",
      "maxdom      0\n",
      "dfrange     0\n",
      "modindx     0\n",
      "label       0\n",
      "dtype: int64\n",
      "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
      "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
      "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
      "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
      "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
      "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
      "\n",
      "          kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
      "0   274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n",
      "1   634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n",
      "2  1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n",
      "3     4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n",
      "4     4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n",
      "\n",
      "     maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n",
      "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000   male  \n",
      "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632   male  \n",
      "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512   male  \n",
      "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119   male  \n",
      "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274   male  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "          meanfreq           sd       median          Q25          Q75  \\\n",
      "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000   \n",
      "mean      0.180907     0.057126     0.185621     0.140456     0.224765   \n",
      "std       0.029918     0.016652     0.036360     0.048680     0.023639   \n",
      "min       0.039363     0.018363     0.010975     0.000229     0.042946   \n",
      "25%       0.163662     0.041954     0.169593     0.111087     0.208747   \n",
      "50%       0.184838     0.059155     0.190032     0.140286     0.225684   \n",
      "75%       0.199146     0.067020     0.210618     0.175939     0.243660   \n",
      "max       0.251124     0.115273     0.261224     0.247347     0.273469   \n",
      "\n",
      "               IQR         skew         kurt       sp.ent          sfm  \\\n",
      "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000   \n",
      "mean      0.084309     3.140168    36.568461     0.895127     0.408216   \n",
      "std       0.042783     4.240529   134.928661     0.044980     0.177521   \n",
      "min       0.014558     0.141735     2.068455     0.738651     0.036876   \n",
      "25%       0.042560     1.649569     5.669547     0.861811     0.258041   \n",
      "50%       0.094280     2.197101     8.318463     0.901767     0.396335   \n",
      "75%       0.114175     2.931694    13.648905     0.928713     0.533676   \n",
      "max       0.252225    34.725453  1309.612887     0.981997     0.842936   \n",
      "\n",
      "              mode     centroid      meanfun       minfun       maxfun  \\\n",
      "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000   \n",
      "mean      0.165282     0.180907     0.142807     0.036802     0.258842   \n",
      "std       0.077203     0.029918     0.032304     0.019220     0.030077   \n",
      "min       0.000000     0.039363     0.055565     0.009775     0.103093   \n",
      "25%       0.118016     0.163662     0.116998     0.018223     0.253968   \n",
      "50%       0.186599     0.184838     0.140519     0.046110     0.271186   \n",
      "75%       0.221104     0.199146     0.169581     0.047904     0.277457   \n",
      "max       0.280000     0.251124     0.237636     0.204082     0.279114   \n",
      "\n",
      "           meandom       mindom       maxdom      dfrange      modindx  \n",
      "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000  \n",
      "mean      0.829211     0.052647     5.047277     4.994630     0.173752  \n",
      "std       0.525205     0.063299     3.521157     3.520039     0.119454  \n",
      "min       0.007812     0.004883     0.007812     0.000000     0.000000  \n",
      "25%       0.419828     0.007812     2.070312     2.044922     0.099766  \n",
      "50%       0.765795     0.023438     4.992188     4.945312     0.139357  \n",
      "75%       1.177166     0.070312     7.007812     6.992188     0.209183  \n",
      "max       2.957682     0.458984    21.867188    21.843750     0.932374  \n",
      "label\n",
      "male      1584\n",
      "female    1584\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load and Explore the Data\n",
    "# We start by examining the dataset for missing values, data types, and general structure. \n",
    "# From the given description, no missing values are present.\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('voice-classification.csv')\n",
    "\n",
    "# Check basic info\n",
    "print(data.info())\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Preview the data\n",
    "print(data.head())\n",
    "\n",
    "print(data.describe())\n",
    "\n",
    "# Count of each class in the target\n",
    "print(data['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6ea04dd2-be23-4cf8-a32c-c1ccb3d4d28b",
   "metadata": {},
   "source": [
    "# Understanding the Data:\n",
    "\n",
    "# Dataset Description:\n",
    "The dataset contains 3168 records and 21 columns.\n",
    "20 are numerical features derived from audio properties, and the final column (label) indicates the gender of the voice (male or female).\n",
    "\n",
    "# Key Features:\n",
    "Frequency metrics: meanfreq, sd, median, Q25, Q75, etc.\n",
    "Spectral properties: skew, kurt, sp.ent, sfm, etc.\n",
    "Frequency ranges: meanfun, minfun, maxfun, dfrange, etc.\n",
    "Modulation: modindx.\n",
    "\n",
    "# Target Variable:\n",
    "label: A binary output indicating the classification (male or female).\n",
    "\n",
    "# Business Context:\n",
    "Objective: Classify voices into male or female to expedite the selection process for a reality show.\n",
    "Challenge: High volume of data, with 3000+ records, each representing a unique audio sample.\n",
    "\n",
    "# Key Considerations:\n",
    "Accents can vary across speakers, introducing variability.\n",
    "Accurate, fast, and scalable classification is essential for business success."
   ]
  },
  {
   "cell_type": "raw",
   "id": "10313f15-f7d9-4df8-b81b-23c78a66eff3",
   "metadata": {},
   "source": [
    "Best Approach for Supervised Learning:\n",
    "Since the problem is a binary classification task, supervised learning techniques are ideal.\n",
    "\n",
    "Model Selection:\n",
    "Given the dataset size and binary output, consider the following algorithms:\n",
    "\n",
    "Logistic Regression:\n",
    "\n",
    "Simple and interpretable.\n",
    "Suitable if the data shows a linear relationship.\n",
    "Decision Trees (DT):\n",
    "\n",
    "Handles non-linear relationships well.\n",
    "Easy to interpret but prone to overfitting.\n",
    "Random Forest (RF):\n",
    "\n",
    "An ensemble technique improving decision trees by reducing overfitting.\n",
    "Handles non-linear data effectively.\n",
    "Naive Bayes:\n",
    "\n",
    "Based on probability and assumptions of independence.\n",
    "Computationally efficient but might not capture complex interactions.\n",
    "Recommended Approach:\n",
    "Start with Random Forest (RF) because:\n",
    "\n",
    "It is robust to overfitting.\n",
    "Works well with medium-sized datasets like this one.\n",
    "Handles non-linearity effectively.\n",
    "Evaluate other models like Logistic Regression or Decision Trees for comparison.\n",
    "\n",
    "Steps to Implement the Solution:\n",
    "Data Preprocessing:\n",
    "\n",
    "Encode the target variable (label) using LabelEncoder.\n",
    "Scale the numerical features to standardize them using StandardScaler.\n",
    "Train-Test Split:\n",
    "\n",
    "Split the data into training and testing sets (e.g., 80:20).\n",
    "Model Training:\n",
    "\n",
    "Train the models (e.g., RF, Logistic Regression).\n",
    "Use hyperparameter tuning (e.g., GridSearchCV) for the best performance.\n",
    "Model Evaluation:\n",
    "\n",
    "Assess accuracy, precision, recall, F1-score, and confusion matrix.\n",
    "Use cross-validation for reliable performance metrics.\n",
    "Output Prediction:\n",
    "\n",
    "Predict the gender of unseen samples.\n",
    "Automation:\n",
    "\n",
    "Deploy the model for real-time classification to streamline the selection process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df8d028b-bf29-4c62-bdf0-0978f70a52cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9842271293375394\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       317\n",
      "           1       0.98      0.99      0.98       317\n",
      "\n",
      "    accuracy                           0.98       634\n",
      "   macro avg       0.98      0.98      0.98       634\n",
      "weighted avg       0.98      0.98      0.98       634\n",
      "\n",
      "Confusion Matrix:\n",
      " [[311   6]\n",
      " [  4 313]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "data['label'] = label_encoder.fit_transform(data['label'])  # male=1, female=0\n",
    "\n",
    "# Split features and target\n",
    "X = data.drop(columns=['label'])\n",
    "y = data['label']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "#  By default, it uses the CART (Classification and Regression Tree) algorithm, which employs the Gini Index as the criterion for splitting unless explicitly specified otherwise.\n",
    "#Default Parameters of RandomForestClassifier\n",
    "#Criterion: 'gini' (splits are based on minimizing the Gini Impurity).\n",
    "#Max Depth: None (trees are grown until all leaves are pure or contain less than min_samples_split samples).\n",
    "#Number of Estimators (n_estimators): 100 (the number of trees in the forest).\n",
    "#Min Samples Split: 2 (minimum samples required to split a node).\n",
    "#Min Samples Leaf: 1 (minimum samples required in a leaf node).\n",
    "#Bootstrap: True (samples are drawn with replacement for building each tree).\n",
    "#Max Features: sqrt (number of features considered for the best split\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy: \", accuracy) \n",
    "print(\"\\nClassification report:\\n\", classification_rep)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "978c29df-c2b8-4a9a-8f79-b1c04b48bd96",
   "metadata": {},
   "source": [
    "Random Forest Model Performance:\n",
    "\n",
    "Accuracy: The model achieved an accuracy of 98.42%, which is excellent for this classification task.\n",
    "\n",
    "Classification Report:\n",
    "Precision:\n",
    "Class 0 (Female): 99%\n",
    "Class 1 (Male): 98%\n",
    "Recall:\n",
    "Class 0 (Female): 98%\n",
    "Class 1 (Male): 99%\n",
    "F1-Score: 98% for both classes.\n",
    "The model is balanced across both classes, with no significant performance disparity.\n",
    "\n",
    "Confusion Matrix:\n",
    "[[311,   6],  # 311 correctly classified as Female, 6 misclassified as Male\n",
    " [  4, 313]]  # 313 correctly classified as Male, 4 misclassified as Female\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4e27c1-de11-4400-8d43-2f03e81d76b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4eac47f8-98c7-4b1f-bc43-87cabda70f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akram\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\ma\\core.py:2881: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'max_depth': 10,\n",
       "  'max_features': 'sqrt',\n",
       "  'min_samples_leaf': 2,\n",
       "  'min_samples_split': 5,\n",
       "  'n_estimators': 200},\n",
       " np.float64(0.9779038130208699))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Initialize the GridSearchCV object\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    verbose=1,\n",
    "    n_jobs=-1  # Use all available processors\n",
    ")\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the corresponding score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "best_params, best_score\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6c302b6a-0350-4e41-a78b-1bf57d5b7524",
   "metadata": {},
   "source": [
    "Best Hyperparameters:\n",
    "max_depth: 10\n",
    "max_features: 'sqrt' (square root of the total features considered for splits).\n",
    "min_samples_leaf: 2 (minimum samples at each leaf node).\n",
    "min_samples_split: 5 (minimum samples required to split an internal node).\n",
    "n_estimators: 200 (number of trees in the forest).\n",
    "Best Cross-Validation Accuracy:\n",
    "Accuracy: ~97.79%\n",
    "This indicates that the tuned model improves the balance between model complexity and generalization.\n",
    "\n",
    "We can now train a new Random Forest model using these optimal hyperparameters and evaluate its performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed33bfb0-88e4-41ff-b915-ef591c3323f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9842271293375394\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       317\n",
      "           1       0.98      0.99      0.98       317\n",
      "\n",
      "    accuracy                           0.98       634\n",
      "   macro avg       0.98      0.98      0.98       634\n",
      "weighted avg       0.98      0.98      0.98       634\n",
      "\n",
      "Confusion Matrix:\n",
      " [[311   6]\n",
      " [  4 313]]\n"
     ]
    }
   ],
   "source": [
    "# Train the Random Forest model with optimal hyperparameters\n",
    "optimized_rf_model = RandomForestClassifier(\n",
    "    max_depth=10,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=5,\n",
    "    n_estimators=200,\n",
    "    random_state=42\n",
    ")\n",
    "optimized_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = optimized_rf_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy: \", accuracy) \n",
    "print(\"\\nClassification report:\\n\", classification_rep)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d4ddcdb-8079-44e7-9918-0edd32eef5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>meanfun</td>\n",
       "      <td>0.356969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IQR</td>\n",
       "      <td>0.223698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q25</td>\n",
       "      <td>0.140238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sd</td>\n",
       "      <td>0.071615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sp.ent</td>\n",
       "      <td>0.038153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sfm</td>\n",
       "      <td>0.029485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meanfreq</td>\n",
       "      <td>0.018355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>centroid</td>\n",
       "      <td>0.017907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mode</td>\n",
       "      <td>0.016404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>median</td>\n",
       "      <td>0.013660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q75</td>\n",
       "      <td>0.009451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>maxdom</td>\n",
       "      <td>0.009250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>minfun</td>\n",
       "      <td>0.009126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dfrange</td>\n",
       "      <td>0.007637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kurt</td>\n",
       "      <td>0.007432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>skew</td>\n",
       "      <td>0.007386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mindom</td>\n",
       "      <td>0.007065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>meandom</td>\n",
       "      <td>0.006710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>modindx</td>\n",
       "      <td>0.005713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>maxfun</td>\n",
       "      <td>0.003746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature  Importance\n",
       "12   meanfun    0.356969\n",
       "5        IQR    0.223698\n",
       "3        Q25    0.140238\n",
       "1         sd    0.071615\n",
       "8     sp.ent    0.038153\n",
       "9        sfm    0.029485\n",
       "0   meanfreq    0.018355\n",
       "11  centroid    0.017907\n",
       "10      mode    0.016404\n",
       "2     median    0.013660\n",
       "4        Q75    0.009451\n",
       "17    maxdom    0.009250\n",
       "13    minfun    0.009126\n",
       "18   dfrange    0.007637\n",
       "7       kurt    0.007432\n",
       "6       skew    0.007386\n",
       "16    mindom    0.007065\n",
       "15   meandom    0.006710\n",
       "19   modindx    0.005713\n",
       "14    maxfun    0.003746"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve feature importances from the optimized Random Forest model\n",
    "feature_importances = optimized_rf_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36f834f0-9819-48bc-a475-c89524f329a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.9652797504248459), np.float64(0.9662271193704808))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validation for default Random Forest model\n",
    "default_rf_cv_scores = cross_val_score(rf_model, X_scaled, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Cross-validation for optimized Random Forest model\n",
    "optimized_rf_cv_scores = cross_val_score(optimized_rf_model, X_scaled, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Compare mean accuracy from cross-validation\n",
    "default_mean_accuracy = default_rf_cv_scores.mean()\n",
    "optimized_mean_accuracy = optimized_rf_cv_scores.mean()\n",
    "\n",
    "default_mean_accuracy, optimized_mean_accuracy"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f4e8352a-9820-4ddb-8719-34a5ad207b7e",
   "metadata": {},
   "source": [
    "Cross-Validation Results:\n",
    "Default Random Forest Model: Mean accuracy from 5-fold cross-validation: 96.53%\n",
    "Optimized Random Forest Model: Mean accuracy from 5-fold cross-validation: 96.62%\n",
    "Observations:\n",
    "The optimized model shows a slight improvement in cross-validation accuracy compared to the default model.\n",
    "The difference in performance is minimal, indicating that the default model was already performing well.\n",
    "The optimized model may offer better generalization and efficiency due to hyperparameter tuning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
